{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data ...\r\n"
     ]
    }
   ],
   "source": [
    "%% Machine Learning Online Class - Exercise 3 | Part 1: One-vs-all\n",
    "\n",
    "%  Instructions\n",
    "%  ------------\n",
    "% \n",
    "%  This file contains code that helps you get started on the\n",
    "%  linear exercise. You will need to complete the following functions \n",
    "%  in this exericse:\n",
    "%\n",
    "%     lrCostFunction.m (logistic regression cost function)\n",
    "%     oneVsAll.m\n",
    "%     predictOneVsAll.m\n",
    "%     predict.m\n",
    "%\n",
    "%  For this exercise, you will not need to change any code in this file,\n",
    "%  or any other files other than those mentioned above.\n",
    "%\n",
    "\n",
    "%% Initialization\n",
    "%clear ; close all; clc\n",
    "\n",
    "%% Setup the parameters you will use for this part of the exercise\n",
    "input_layer_size  = 400;  % 20x20 Input Images of Digits\n",
    "num_labels = 10;          % 10 labels, from 1 to 10   \n",
    "                          % (note that we have mapped \"0\" to label 10)\n",
    "\n",
    "%% =========== Part 1: Loading and Visualizing Data =============\n",
    "%  We start the exercise by first loading and visualizing the dataset. \n",
    "%  You will be working with a dataset that contains handwritten digits.\n",
    "%\n",
    "\n",
    "% Load Training Data\n",
    "fprintf('Loading Data ...\\n')\n",
    "\n",
    "load('exercises/ex3/ex3data1.mat'); % training data stored in arrays X, y\n",
    "m = size(X, 1);\n",
    "\n",
    "% Randomly select 100 data points to display\n",
    "%rand_indices = randperm(m);\n",
    "%sel = X(rand_indices(1:100), :);\n",
    "\n",
    "%displayData(sel);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "\n",
      "   0.98201   0.99331   0.99753\n",
      "\n",
      "ans =\n",
      "\n",
      "   0.98201   0.99331   0.99753\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% first sigmoid function\n",
    "function g = sigmoid2(z)\n",
    "    %SIGMOID Compute sigmoid functoon\n",
    "    %   J = SIGMOID(z) computes the sigmoid of z.\n",
    "\n",
    "    % You need to return the following variables correctly\n",
    "\n",
    "    g = zeros(size(z));\n",
    "\n",
    "    % ====================== YOUR CODE HERE ======================\n",
    "    % Instructions: Compute the sigmoid of each value of z (z can be a matrix,\n",
    "    %               vector or scalar).\n",
    "\n",
    "\n",
    "    for i = 1:rows(z)\n",
    "        for j = 1:columns(z)\n",
    "            g(i,j) = 1 / (1 + e^-z(i,j));\n",
    "        end\n",
    "    end    \n",
    "\n",
    "    #z(1,1)\n",
    "\n",
    "\n",
    "    % =============================================================\n",
    "end\n",
    "\n",
    "function g = sigmoid(z)\n",
    "%SIGMOID Compute sigmoid functoon\n",
    "%   J = SIGMOID(z) computes the sigmoid of z.\n",
    "\n",
    "g = 1.0 ./ (1.0 + exp(-z));\n",
    "end\n",
    "\n",
    "test = [4 5 6];\n",
    "\n",
    "sigmoid2(test)\n",
    "\n",
    "sigmoid(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lrCostFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j =  7.6832\n",
      "g =\n",
      "\n",
      "   0.31722\n",
      "  -0.12768\n",
      "   2.64812\n",
      "   4.23787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "function [J, grad] = lrCostFunction(theta, X, y, lambda)\n",
    "    %LRCOSTFUNCTION Compute cost and gradient for logistic regression with \n",
    "    %regularization\n",
    "    %   J = LRCOSTFUNCTION(theta, X, y, lambda) computes the cost of using\n",
    "    %   theta as the parameter for regularized logistic regression and the\n",
    "    %   gradient of the cost w.r.t. to the parameters. \n",
    "\n",
    "    % Initialize some useful values\n",
    "    m = length(y); % number of training examples\n",
    "\n",
    "    % You need to return the following variables correctly \n",
    "    J = 0;\n",
    "    grad = zeros(size(theta));\n",
    "\n",
    "    % ====================== YOUR CODE HERE ======================\n",
    "    % Instructions: Compute the cost of a particular choice of theta.\n",
    "    %               You should set J to the cost.\n",
    "    %               Compute the partial derivatives and set grad to the partial\n",
    "    %               derivatives of the cost w.r.t. each parameter in theta\n",
    "    %\n",
    "    % Hint: The computation of the cost function and gradients can be\n",
    "    %       efficiently vectorized. For example, consider the computation\n",
    "    %\n",
    "    %           sigmoid(X * theta)\n",
    "    %\n",
    "    %       Each row of the resulting matrix will contain the value of the\n",
    "    %       prediction for that example. You can make use of this to vectorize\n",
    "    %       the cost function and gradient computations. \n",
    "    %\n",
    "    % Hint: When computing the gradient of the regularized cost function, \n",
    "    %       there're many possible vectorized solutions, but one solution\n",
    "    %       looks like:\n",
    "    %           grad = (unregularized gradient for logistic regression)\n",
    "    %           temp = theta; \n",
    "    %           temp(1) = 0;   % because we don't add anything for j = 0  \n",
    "    %           grad = grad + YOUR_CODE_HERE (using the temp variable)\n",
    "    %\n",
    "    % ============================================================\n",
    "\n",
    "    %grad = grad(:);\n",
    "\n",
    "    XOK = X(:, 2:end);\n",
    "    thetaOK = theta(2:end,:);\n",
    "    h = sigmoid(X*theta);\n",
    "    \n",
    "    J = ( -y'*log(h) - (1-y)'*log(1-h) ) / m + lambda * sum(thetaOK.^2) / (2*m);\n",
    "\n",
    "    grad(1,:) = X(:,1)'*(h - y) / m;\n",
    "    grad(2:end,:) = XOK'*(h - y) / m + lambda*thetaOK / m;\n",
    "\n",
    "end\n",
    "\n",
    "Xtest = [ones(3,1) magic(3)];\n",
    "ytest = [1 0 1]';\n",
    "thetatest = [-2 -1 1 2]';\n",
    "\n",
    "[j, g] = lrCostFunction(thetatest, Xtest, ytest, 3)\n",
    "\n",
    "%[j g] = costFunctionReg(thetatest, Xtest, ytest, 0);\n",
    "\n",
    "%j = 7.6832\n",
    "%\n",
    "%g =\n",
    "%  0.31722\n",
    "%  -0.12768\n",
    "%  2.64812\n",
    "%  4.23787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J =  2.5348\n",
      "grad =\n",
      "\n",
      "   0.14656\n",
      "  -0.54856\n",
      "   0.72472\n",
      "   1.39800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% test cases\n",
    "% input\n",
    "theta = [-2; -1; 1; 2];\n",
    "X = [ones(5,1) reshape(1:15,5,3)/10];\n",
    "y = [1;0;1;0;1] >= 0.5;       % creates a logical array\n",
    "lambda = 3;\n",
    "[J grad] = lrCostFunction(theta, X, y, lambda)\n",
    "\n",
    "% results\n",
    "%J =  2.5348\n",
    "%grad =\n",
    "%\n",
    "%   0.14656\n",
    "%  -0.54856\n",
    "%   0.72472\n",
    "%   1.39800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: lrCostFunction: operator *: nonconformant arguments (op1 is 5x4, op2 is 3x4)\n",
      "error: called from\n",
      "    lrCostFunction at line 44 column 7\n",
      "    oneVsAll> at line -1 column -1\n",
      "    fminunc at line 162 column 8\n",
      "    oneVsAll at line 56 column 16\n",
      "error: evaluating argument list element number 1\n",
      "error: called from\n",
      "    lrCostFunction at line 44 column 7\n",
      "    oneVsAll> at line -1 column -1\n",
      "    fminunc at line 162 column 8\n",
      "    oneVsAll at line 56 column 16\n"
     ]
    }
   ],
   "source": [
    "%% ============ Part 2: Vectorize Logistic Regression ============\n",
    "%  In this part of the exercise, you will reuse your logistic regression\n",
    "%  code from the last exercise. You task here is to make sure that your\n",
    "%  regularized logistic regression implementation is vectorized. After\n",
    "%  that, you will implement one-vs-all classification for the handwritten\n",
    "%  digit dataset.\n",
    "%\n",
    "\n",
    "function [all_theta] = oneVsAll(X, y, num_labels, lambda)\n",
    "    %ONEVSALL trains multiple logistic regression classifiers and returns all\n",
    "    %the classifiers in a matrix all_theta, where the i-th row of all_theta \n",
    "    %corresponds to the classifier for label i\n",
    "    %   [all_theta] = ONEVSALL(X, y, num_labels, lambda) trains num_labels\n",
    "    %   logisitc regression classifiers and returns each of these classifiers\n",
    "    %   in a matrix all_theta, where the i-th row of all_theta corresponds \n",
    "    %   to the classifier for label i\n",
    "\n",
    "    % Some useful variables\n",
    "    m = size(X, 1);\n",
    "    n = size(X, 2);\n",
    "\n",
    "    % You need to return the following variables correctly \n",
    "    all_theta = zeros(num_labels, n + 1);\n",
    "\n",
    "    % Add ones to the X data matrix\n",
    "    X = [ones(m, 1) X];\n",
    "\n",
    "    % ====================== YOUR CODE HERE ======================\n",
    "    % Instructions: You should complete the following code to train num_labels\n",
    "    %               logistic regression classifiers with regularization\n",
    "    %               parameter lambda. \n",
    "    %\n",
    "    % Hint: theta(:) will return a column vector.\n",
    "    %\n",
    "    % Hint: You can use y == c to obtain a vector of 1's and 0's that tell use \n",
    "    %       whether the ground truth is true/false for this class.\n",
    "    %\n",
    "    % Note: For this assignment, we recommend using fmincg to optimize the cost\n",
    "    %       function. It is okay to use a for-loop (for c = 1:num_labels) to\n",
    "    %       loop over the different classes.\n",
    "    %\n",
    "    %       fmincg works similarly to fminunc, but is more efficient when we\n",
    "    %       are dealing with large number of parameters.\n",
    "    %\n",
    "    % Example Code for fmincg:\n",
    "    %\n",
    "    %     % Set Initial theta\n",
    "    %     initial_theta = zeros(n + 1, 1);\n",
    "    %     \n",
    "    %     % Set options for fminunc\n",
    "    %     options = optimset('GradObj', 'on', 'MaxIter', 50);\n",
    "    % \n",
    "    %     % Run fmincg to obtain the optimal theta\n",
    "    %     % This function will return theta and the cost \n",
    "    %     [theta] = ...\n",
    "    %         fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), ...\n",
    "    %                 initial_theta, options);\n",
    "    %\n",
    "\n",
    "    initial_theta = all_theta;\n",
    "    options = optimset('GradObj', 'on', 'MaxIter', 50);\n",
    "\n",
    "    for c = 1:num_labels\n",
    "        [theta] = fminunc(@(t)(lrCostFunction(t, X, (y == c), lambda)), initial_theta, options);\n",
    "    end\n",
    "    \n",
    "\n",
    "    % =========================================================================\n",
    "\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "%lambda = 0.1;\n",
    "%[all_theta] = oneVsAll(X, y, num_labels, lambda);\n",
    "\n",
    "% test case\n",
    "%input:\n",
    "X = [magic(3) ; sin(1:3); cos(1:3)];\n",
    "y = [1; 2; 2; 1; 3];\n",
    "num_labels = 3;\n",
    "lambda = 0.1;\n",
    "[all_theta] = oneVsAll(X, y, num_labels, lambda)\n",
    "%output:\n",
    "%all_theta =\n",
    "%  -0.559478   0.619220  -0.550361  -0.093502\n",
    "%  -5.472920  -0.471565   1.261046   0.634767\n",
    "%   0.068368  -0.375582  -1.652262  -1.410138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "function p = predictOneVsAll(all_theta, X)\n",
    "%PREDICT Predict the label for a trained one-vs-all classifier. The labels \n",
    "%are in the range 1..K, where K = size(all_theta, 1). \n",
    "%  p = PREDICTONEVSALL(all_theta, X) will return a vector of predictions\n",
    "%  for each example in the matrix X. Note that X contains the examples in\n",
    "%  rows. all_theta is a matrix where the i-th row is a trained logistic\n",
    "%  regression theta vector for the i-th class. You should set p to a vector\n",
    "%  of values from 1..K (e.g., p = [1; 3; 1; 2] predicts classes 1, 3, 1, 2\n",
    "%  for 4 examples) \n",
    "\n",
    "m = size(X, 1);\n",
    "num_labels = size(all_theta, 1);\n",
    "\n",
    "% You need to return the following variables correctly \n",
    "p = zeros(size(X, 1), 1);\n",
    "\n",
    "% Add ones to the X data matrix\n",
    "X = [ones(m, 1) X];\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Complete the following code to make predictions using\n",
    "%               your learned logistic regression parameters (one-vs-all).\n",
    "%               You should set p to a vector of predictions (from 1 to\n",
    "%               num_labels).\n",
    "%\n",
    "% Hint: This code can be done all vectorized using the max function.\n",
    "%       In particular, the max function can also return the index of the \n",
    "%       max element, for more information see 'help max'. If your examples \n",
    "%       are in rows, then, you can use max(A, [], 2) to obtain the max \n",
    "%       for each row.\n",
    "%       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "% =========================================================================\n",
    "\n",
    "\n",
    "end\n",
    "\n",
    "%% ================ Part 3: Predict for One-Vs-All ================\n",
    "%  After ...\n",
    "pred = predictOneVsAll(all_theta, X);\n",
    "\n",
    "fprintf('\\nTraining Set Accuracy: %f\\n', mean(double(pred == y)) * 100);\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "0.16.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
