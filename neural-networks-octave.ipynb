{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data ...\r\n"
     ]
    }
   ],
   "source": [
    "%% Machine Learning Online Class - Exercise 3 | Part 1: One-vs-all\n",
    "\n",
    "%  Instructions\n",
    "%  ------------\n",
    "% \n",
    "%  This file contains code that helps you get started on the\n",
    "%  linear exercise. You will need to complete the following functions \n",
    "%  in this exericse:\n",
    "%\n",
    "%     lrCostFunction.m (logistic regression cost function)\n",
    "%     oneVsAll.m\n",
    "%     predictOneVsAll.m\n",
    "%     predict.m\n",
    "%\n",
    "%  For this exercise, you will not need to change any code in this file,\n",
    "%  or any other files other than those mentioned above.\n",
    "%\n",
    "\n",
    "%% Initialization\n",
    "%clear ; close all; clc\n",
    "\n",
    "%% Setup the parameters you will use for this part of the exercise\n",
    "input_layer_size  = 400;  % 20x20 Input Images of Digits\n",
    "num_labels = 10;          % 10 labels, from 1 to 10   \n",
    "                          % (note that we have mapped \"0\" to label 10)\n",
    "\n",
    "%% =========== Part 1: Loading and Visualizing Data =============\n",
    "%  We start the exercise by first loading and visualizing the dataset. \n",
    "%  You will be working with a dataset that contains handwritten digits.\n",
    "%\n",
    "\n",
    "% Load Training Data\n",
    "fprintf('Loading Data ...\\n')\n",
    "\n",
    "load('exercises/ex3/ex3data1.mat'); % training data stored in arrays X, y\n",
    "m = size(X, 1);\n",
    "\n",
    "% Randomly select 100 data points to display\n",
    "%rand_indices = randperm(m);\n",
    "%sel = X(rand_indices(1:100), :);\n",
    "\n",
    "%displayData(sel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%% ============ Part 2: Vectorize Logistic Regression ============\n",
    "%  In this part of the exercise, you will reuse your logistic regression\n",
    "%  code from the last exercise. You task here is to make sure that your\n",
    "%  regularized logistic regression implementation is vectorized. After\n",
    "%  that, you will implement one-vs-all classification for the handwritten\n",
    "%  digit dataset.\n",
    "%\n",
    "\n",
    "function [all_theta] = oneVsAll(X, y, num_labels, lambda)\n",
    "    %ONEVSALL trains multiple logistic regression classifiers and returns all\n",
    "    %the classifiers in a matrix all_theta, where the i-th row of all_theta \n",
    "    %corresponds to the classifier for label i\n",
    "    %   [all_theta] = ONEVSALL(X, y, num_labels, lambda) trains num_labels\n",
    "    %   logisitc regression classifiers and returns each of these classifiers\n",
    "    %   in a matrix all_theta, where the i-th row of all_theta corresponds \n",
    "    %   to the classifier for label i\n",
    "\n",
    "    % Some useful variables\n",
    "    m = size(X, 1);\n",
    "    n = size(X, 2);\n",
    "\n",
    "    % You need to return the following variables correctly \n",
    "    all_theta = zeros(num_labels, n + 1);\n",
    "\n",
    "    % Add ones to the X data matrix\n",
    "    X = [ones(m, 1) X];\n",
    "\n",
    "    % ====================== YOUR CODE HERE ======================\n",
    "    % Instructions: You should complete the following code to train num_labels\n",
    "    %               logistic regression classifiers with regularization\n",
    "    %               parameter lambda. \n",
    "    %\n",
    "    % Hint: theta(:) will return a column vector.\n",
    "    %\n",
    "    % Hint: You can use y == c to obtain a vector of 1's and 0's that tell use \n",
    "    %       whether the ground truth is true/false for this class.\n",
    "    %\n",
    "    % Note: For this assignment, we recommend using fmincg to optimize the cost\n",
    "    %       function. It is okay to use a for-loop (for c = 1:num_labels) to\n",
    "    %       loop over the different classes.\n",
    "    %\n",
    "    %       fmincg works similarly to fminunc, but is more efficient when we\n",
    "    %       are dealing with large number of parameters.\n",
    "    %\n",
    "    % Example Code for fmincg:\n",
    "    %\n",
    "    %     % Set Initial theta\n",
    "    %     initial_theta = zeros(n + 1, 1);\n",
    "    %     \n",
    "    %     % Set options for fminunc\n",
    "    %     options = optimset('GradObj', 'on', 'MaxIter', 50);\n",
    "    % \n",
    "    %     % Run fmincg to obtain the optimal theta\n",
    "    %     % This function will return theta and the cost \n",
    "    %     [theta] = ...\n",
    "    %         fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), ...\n",
    "    %                 initial_theta, options);\n",
    "    %\n",
    "\n",
    "\n",
    "\n",
    "    % =========================================================================\n",
    "\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "lambda = 0.1;\n",
    "[all_theta] = oneVsAll(X, y, num_labels, lambda);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "function p = predictOneVsAll(all_theta, X)\n",
    "%PREDICT Predict the label for a trained one-vs-all classifier. The labels \n",
    "%are in the range 1..K, where K = size(all_theta, 1). \n",
    "%  p = PREDICTONEVSALL(all_theta, X) will return a vector of predictions\n",
    "%  for each example in the matrix X. Note that X contains the examples in\n",
    "%  rows. all_theta is a matrix where the i-th row is a trained logistic\n",
    "%  regression theta vector for the i-th class. You should set p to a vector\n",
    "%  of values from 1..K (e.g., p = [1; 3; 1; 2] predicts classes 1, 3, 1, 2\n",
    "%  for 4 examples) \n",
    "\n",
    "m = size(X, 1);\n",
    "num_labels = size(all_theta, 1);\n",
    "\n",
    "% You need to return the following variables correctly \n",
    "p = zeros(size(X, 1), 1);\n",
    "\n",
    "% Add ones to the X data matrix\n",
    "X = [ones(m, 1) X];\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Complete the following code to make predictions using\n",
    "%               your learned logistic regression parameters (one-vs-all).\n",
    "%               You should set p to a vector of predictions (from 1 to\n",
    "%               num_labels).\n",
    "%\n",
    "% Hint: This code can be done all vectorized using the max function.\n",
    "%       In particular, the max function can also return the index of the \n",
    "%       max element, for more information see 'help max'. If your examples \n",
    "%       are in rows, then, you can use max(A, [], 2) to obtain the max \n",
    "%       for each row.\n",
    "%       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "% =========================================================================\n",
    "\n",
    "\n",
    "end\n",
    "\n",
    "%% ================ Part 3: Predict for One-Vs-All ================\n",
    "%  After ...\n",
    "pred = predictOneVsAll(all_theta, X);\n",
    "\n",
    "fprintf('\\nTraining Set Accuracy: %f\\n', mean(double(pred == y)) * 100);\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "0.16.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
