{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "Formal definition by Tom M. Mitchell:\n",
    "> A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\n",
    "\n",
    "Machine is not initially (or ever) perfect at performing the given task so the function that the machine comes up with for performing the task is called a **hypothesis function**. Another function is used to train the machine, to improve the hypothesis function. As the machine is training, the performance of each prediction attempt can be measured with a **cost function**.\n",
    "\n",
    "Hypothesis function is often denoted as $h_\\theta(x)$, where as the cost function is $J(\\theta_0,\\theta_1)$\n",
    "\n",
    "**Gradient descent** is one training algorithm. It uses cost function to specify such theta values that the cost function reaches minimum (best theta values).\n",
    "\n",
    "$$\\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta_0,\\theta_1)$$\n",
    "\n",
    "In simpler form:\n",
    "\n",
    "$$\\theta_j:=\\theta_j-\\alpha[Slope\\,of\\,the\\,cost\\,function]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "General form of the **hyphothesis function** in Linear regression:\n",
    "\n",
    "$$\\hat{y}=h_\\theta(x)=\\theta_0+\\theta_1x$$\n",
    "\n",
    "Values of $\\theta_0$ and $\\theta_1$ are modified as the machine learns.\n",
    "\n",
    "**Cost function**:\n",
    "\n",
    "$$J(\\theta_0,\\theta_1)=\\frac{1}{2m}\\sum_{i=1}^m(\\hat{y}_i-y_i)^2 = \\frac{1}{2m}\\sum_{i=1}^m(h_\\theta(x_i)-y_i)^2$$\n",
    "\n",
    "Cost function uses Mean squared error. Division by 2 to make it convenient to calculate gradient descent (derivative of $x^2=2x$).\n",
    "\n",
    "**Gradient descent**:\n",
    "$$\\theta_0:=\\theta_0-\\alpha\\frac{1}{m}\\sum^m_{i=1}(h_\\theta(x_i)-y_i)$$\n",
    "\n",
    "$$\\theta_1:=\\theta_1-\\alpha\\frac{1}{m}\\sum^m_{i=1}((h_\\theta(x_i)-y_i)x_i)$$\n",
    "\n",
    "Above examples represent linear regression with only one variable x (univariate linear regression). For linear regression with multible variables (multivariate linear regression) the hypothesis function looks like this:\n",
    "$$h_\\theta(x)=\\theta_0+\\theta_1x_1+\\theta_2x_2+\\theta_3x_3+...+\\theta_nx_n$$\n",
    "\n",
    "Using matrix multiplication this can be represented as:\n",
    "$$\n",
    "    h_\\theta(x)=\n",
    "    \\begin{bmatrix}\n",
    "    \\theta_0 & \\theta_1 & \\ldots & \\theta_n \\\\\n",
    "    \\end{bmatrix}        \n",
    "    \\begin{bmatrix}\n",
    "    x_0 \\\\\n",
    "    x_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\end{bmatrix}\n",
    "    =\\theta^Tx\n",
    "$$\n",
    "\n",
    "We can assume $x_0=1$, which makes matrices of training inputs and theta same size, so they can be multiplied together:\n",
    "$$\n",
    "    X=\n",
    "    \\begin{bmatrix}\n",
    "    x_0 \\\\\n",
    "    x_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    x_n \\\\    \n",
    "    \\end{bmatrix}\n",
    "    ,\\,\n",
    "    \\theta=\n",
    "    \\begin{bmatrix}\n",
    "    \\theta_0 \\\\\n",
    "    \\theta_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\theta_n \\\\\n",
    "    \\end{bmatrix}    \n",
    "$$\n",
    "\n",
    "**Vectorized cost function**:\n",
    "\n",
    "$$J(\\theta) = \\dfrac {1}{2m} (X\\theta - \\vec{y})^{T} (X\\theta - \\vec{y})$$\n",
    "\n",
    "Where $\\vec{y}$ denotes the vector of all y values.\n",
    "\n",
    "**Vectorised gradient descent**:\n",
    "\n",
    "$$\\theta := \\theta - \\frac{\\alpha}{m} X^{T} (X\\theta - \\vec{y})$$\n",
    "\n",
    "**Feature normalization** can be used to transform input values so that they are on the same scale. This improves efficiency of the gradient descent algorithm. Feature normalization can be done by using two techniques together: **Mean normalization** subtracts the mean input value $\\mu_i$, **feature scaling** divides by range (eg. max - min) $s_i$ or standard deviation.\n",
    "\n",
    "$$x_i := \\dfrac{x_i - \\mu_i}{s_i}$$\n",
    "\n",
    "Where $μ_i$ is the average of all the values for feature (i) and $s_i$ is the range of values (max - min), or $s_i$ is the standard deviation.\n",
    "\n",
    "Amount of features can be increased (if feasible) by producing new features from current features.\n",
    "\n",
    "Hypothesis function can also be transformed from a straight line (function of degree 1) into a curved line (eg. function of 2 or more degrees or square root function) if feasible. This is called **Polynomial regression**. For example:\n",
    "\n",
    "$$h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_1^2 + \\theta_3 x_1^3$$\n",
    "\n",
    "Polynomial regression increases the range of input values (exponentially) so feature scaling becomes very important. It also increases the chance of overfitting.\n",
    "\n",
    "**Normal equation** is a method of finding the optimum theta without iteration.\n",
    "\n",
    "$$\\theta = (X^T X)^{-1}X^T y$$\n",
    "\n",
    "| **Gradient Descent**       | **Normal Equation**                      |\n",
    "| -------------------------- | ---------------------------------------- |\n",
    "| Need to choose alpha       | No need to choose alpha                  |\n",
    "| Needs many iterations      | No need to iterate                       |\n",
    "| O (kn2)                    | O (n3), need to calculate inverse of XTX |\n",
    "| Works well when n is large | Slow if n is very large (over 10,000)    |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "Logistic regression is a popular algorithm to use with **classification** problems where y has discrete values (in contrast to continuous values in regression problems). The name \"logistic regression\" may be a bit confusing since it seems to relate to regression problems, which (as noted above) is not the case.\n",
    "\n",
    "Linear regression could be used with classification problems by mapping eg. all values greater than 0.5 as 1 and all less than 0.5 as 1, but this wouldn't work well because classification is not actually a linear function.\n",
    "\n",
    "**Hypothesis**\n",
    "$$0 \\leq h_\\theta (x) \\leq 1$$\n",
    "\n",
    "$$h_\\theta(x)=g(z)=\\dfrac{1}{1+e^{-z}}$$\n",
    "\n",
    "Where $z = \\theta^T x$ (ie. the matrix representation of the hypothesis function in linear regression). \n",
    "\n",
    "The **Sigmoid function** g(z) (also called **logistic function**), maps any real number to the (0, 1) interval, making it useful for transforming an arbitrary-valued function into a function better suited for classification.\n",
    "\n",
    "![alt text](https://share.coursera.org/wiki/images/b/b9/Logistic_function.png \"Sigmoid function\")\n",
    "\n",
    "If we map all output of g(z) so that $(\\geq0.5)\\rightarrow 1$ and $(<0.5)\\rightarrow 0$, it leads that $\\theta^T x \\geq 0 \\Rightarrow y = 1$ and $\\theta^T x < 0 \\Rightarrow y = 0$.\n",
    "\n",
    "The **decision boundary** is the line that separates the area where y=0 and where y=1. It is created by our hypothesis function.\n",
    "\n",
    "**Cost function**\n",
    "\n",
    "We cannot use the same cost function that we use for linear regression because the Logistic Function will cause the output to be wavy, causing many local optima. In other words, it will not be a convex function.\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "    & J(\\theta) = \\dfrac{1}{m} \\sum_{i=1}^m \\mathrm{Cost}(h_\\theta(x^{(i)}),y^{(i)}) \\newline\n",
    "    & \\mathrm{Cost}(h_\\theta(x),y) = -\\log(h_\\theta(x)) \\; & \\text{if y = 1} \\newline\n",
    "    & \\mathrm{Cost}(h_\\theta(x),y) = -\\log(1-h_\\theta(x)) \\; & \\text{if y = 0}\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "writing the cost function in this way guarantees that J(θ) is convex for logistic regression.\n",
    "\n",
    "We can compress our cost function's two conditional cases into one case:\n",
    "\n",
    "$$\\mathrm{Cost}(h_\\theta(x),y) = - y \\; \\log(h_\\theta(x)) - (1 - y) \\log(1 - h_\\theta(x))$$\n",
    "\n",
    "Notice that when y is equal to 1, then the second term $(1-y)\\log(1-h_\\theta(x))$ will be zero and will not affect the result. If y is equal to 0, then the first term $-y \\log(h_\\theta(x))$ will be zero and will not affect the result.\n",
    "\n",
    "We can fully write out our entire cost function as follows:\n",
    "\n",
    "$$J(\\theta) = - \\frac{1}{m} \\displaystyle \\sum_{i=1}^m [y^{(i)}\\log (h_\\theta (x^{(i)})) + (1 - y^{(i)})\\log (1 - h_\\theta(x^{(i)}))]$$\n",
    "\n",
    "Vectorized implementation:\n",
    "\\begin{align*}\n",
    "& h = g(X\\theta)\\newline\n",
    "& J(\\theta)  = \\frac{1}{m} \\cdot \\left(-y^{T}\\log(h)-(1-y)^{T}\\log(1-h)\\right)\n",
    "\\end{align*}\n",
    "\n",
    "Vectorized partial derivative of the cost function:\n",
    "\n",
    "$$\\nabla J(\\theta) = \\frac{1}{m} \\cdot  X^T \\cdot \\left(g^{\\prime }\\left(X^T\\cdot\\theta\\right) - y\\right)$$\n",
    "\n",
    "**Gradient descent**\n",
    "\n",
    "vectorized implementation is the same as in linear regression except $X\\theta$ is replaced with $g(X \\theta )$:\n",
    "\n",
    "$$\\theta := \\theta - \\frac{\\alpha}{m} X^{T} (g(X \\theta ) - \\vec{y})$$\n",
    "\n",
    "## Regularization\n",
    "\n",
    "![alt text](http://i.stack.imgur.com/t0zit.png \"Sigmoid function\")\n",
    "\n",
    "Lots of features and little data can lead to overfitting.\n",
    "\n",
    "Options for addressing overfitting:\n",
    "1. reduce number of features\n",
    "    - manually\n",
    "    - using a model\n",
    "2. Regularization\n",
    "    - reduce magnitude/values of parameters $\\theta_j$ (by increasing their cost)\n",
    "    - works well when we hava a lot of features but they are all somewhat useful so we don't want to throw them away\n",
    "    \n",
    "Cost of certain parameters can be increased by modifying the cost function:\n",
    "$$min_\\theta\\ \\dfrac{1}{2m}\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2 + 1000\\cdot\\theta_3^2 + 1000\\cdot\\theta_4^2$$\n",
    "\n",
    "We could also regularize all of our theta parameters in a single summation:\n",
    "$$min_\\theta\\ \\dfrac{1}{2m}\\ \\left[ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda\\ \\sum_{j=1}^n \\theta_j^2 \\right]$$\n",
    "\n",
    "The λ, or lambda, is the **regularization parameter**. It determines how much the costs of our theta parameters are inflated.\n",
    "\n",
    "### Regularised linear regression\n",
    "\n",
    "**Gradient descent**\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "    & \\ \\ \\ \\ \\theta_0 := \\theta_0 - \\alpha\\ \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \\newline\n",
    "    & \\ \\ \\ \\ \\theta_j := \\theta_j - \\alpha\\ \\left[ \\left( \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\right) + \\frac{\\lambda}{m}\\theta_j \\right] &\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ j \\in \\lbrace 1,2...n\\rbrace\\newline\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "$\\theta_0$ is separated because there is no reason to penalise it.\n",
    "\n",
    "With some manipulation our update rule can also be represented as:\n",
    "\n",
    "$$\\theta_j := \\theta_j(1 - \\alpha\\frac{\\lambda}{m}) - \\alpha\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$$\n",
    "\n",
    "This makes the second term appear the same as without regularization.\n",
    "\n",
    "**Normal equation**\n",
    "\n",
    "\\begin{align*}\n",
    "& \\theta = \\left( X^TX + \\lambda \\cdot L \\right)^{-1} X^Ty \\newline\n",
    "& \\text{where}\\ \\ L = \n",
    "\\begin{bmatrix}\n",
    " 0 & & & & \\newline\n",
    " & 1 & & & \\newline\n",
    " & & 1 & & \\newline\n",
    " & & & \\ddots & \\newline\n",
    " & & & & 1 \\newline\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "### Regularised logistic regression\n",
    "\n",
    "**Cost function**\n",
    "\n",
    "Just add term at the end:\n",
    "$$J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^m [ y^{(i)}\\ \\log (h_\\theta (x^{(i)})) + (1 - y^{(i)})\\ \\log (1 - h_\\theta(x^{(i)}))] + \\frac{\\lambda}{2m}\\sum_{j=1}^n \\theta_j^2$$\n",
    "\n",
    "**Gradient descent**\n",
    "\n",
    "Identical to linear regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
